{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mavropulokn/functionsHw/blob/main/Python_Advanced_%D0%A4%D1%83%D0%BD%D0%BA%D1%86%D0%B8%D0%B8_%D0%94%D0%BE%D0%BC%D0%B0%D1%88%D0%BD%D0%B5%D0%B5_%D0%B7%D0%B0%D0%B4%D0%B0%D0%BD%D0%B8%D0%B5_(HW).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "MXXTuy_o0sjk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42d45b18-7c0f-4a41-ad8c-f0d1382e185a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 1.9 MB 15.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 62 kB 1.7 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q -U kaggle_environments"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Опишем поведение агента, всегда играющего \"камень\" - это значение 0"
      ],
      "metadata": {
        "id": "0kuo6IOxiRub"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile ablaze.py\n",
        "import numpy as np\n",
        "\n",
        "ablaze_combination_action = 0\n",
        "\n",
        "\n",
        "def ablaze(observation, configuration):\n",
        "    \"\"\"Gets action based on random selection (acts every configuration.signs steps, ablaze cycle).\n",
        "\n",
        "    After configuration.signs steps (combination) a cycle repeats.\n",
        "    Uses the ablaze_combination_action saved during each cycle.\n",
        "    This rock-paper-scissors comparison functionality is so-called agent.\n",
        "    Agent could be used for competition by the kaggle_environments framework.\n",
        "    :param observation: observation object with auxiliary data\n",
        "    :param configuration: configuration object with game configuration\n",
        "    :return: int action, new action selected during ablaze cycle\n",
        "    \"\"\"\n",
        "\n",
        "    # Action to repeat in series (combination) of steps.\n",
        "    global ablaze_combination_action\n",
        "\n",
        "    if observation.step % configuration.signs == 0:\n",
        "        ablaze_combination_action = np.random.randint(0, configuration.signs)\n",
        "    else:\n",
        "        return ablaze_combination_action\n"
      ],
      "metadata": {
        "id": "bqTqV7B92rJ6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f737289f-7243-4bdd-9022-09f7ceccc2d0"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting ablaze.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Попробуем теперь использовать информацию о прошлых действиях противника. Опишем агента, который производит то же самое действие, что и оппонент на прошлом ходу"
      ],
      "metadata": {
        "id": "et1J5hUGigeh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile anti_counter_attack_last_move.py\n",
        "from collections import deque\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "anti_counter_attack_last_move_agent_auxiliary_marker = 1\n",
        "anti_counter_attack_last_move_agent_moves = deque(maxlen=2)\n",
        "opponent_moves = deque(maxlen=1)\n",
        "\n",
        "\n",
        "def anti_counter_attack_last_move(observation, configuration):\n",
        "    \"\"\"Gets action to win the counter_attack_last_move agent.\n",
        "\n",
        "    Detects counter_attack_last_move agent (tested in 3 consecutive rounds).\n",
        "    Uses the queue to save last 2 actions and mark to save the criteria check result.\n",
        "    This rock-paper-scissors comparison functionality is so-called agent.\n",
        "    Agent could be used for competition by the kaggle_environments framework.\n",
        "    :param observation: observation object with auxiliary data\n",
        "    :param configuration: configuration object with game configuration\n",
        "    :return: int action to win counter_attack_last_move agent or random one (in detection criteria isn't verified)\n",
        "    \"\"\"\n",
        "\n",
        "    # Queue to save last 2 actions.\n",
        "    global anti_counter_attack_last_move_agent_moves\n",
        "\n",
        "    # Mark to save the criteria validation.\n",
        "    global anti_counter_attack_last_move_agent_auxiliary_marker\n",
        "\n",
        "    def is_counter_attack_last_move_agent_move_expected_equals_actual(configuration, observation,\n",
        "                                                                      counter_attack_defencemoves):\n",
        "        \"\"\"Gets predicate or to check if the opponent could be counter_attack_last_move agent.\"\"\"\n",
        "        return observation.lastOpponentAction == (\n",
        "                counter_attack_defencemoves.popleft() + 1) % configuration.signs\n",
        "\n",
        "    def act_against_counter_attack_last_move_agent(anti_counter_attack_last_move_agent_moves, configuration):\n",
        "        \"\"\"Gets action against counter_attack_last_move agent, saves action and returns.\"\"\"\n",
        "\n",
        "        action = (anti_counter_attack_last_move_agent_moves.popleft() + 2) % configuration.signs\n",
        "        anti_counter_attack_last_move_agent_moves.append(action)\n",
        "        return action\n",
        "\n",
        "    def is_counter_attack_last_move_agent_detected(anti_counter_attack_last_move_agent_auxiliary_marker,\n",
        "                                                   observation):\n",
        "        \"\"\"Checks the counter_attack_last_move_agent detection criteria has succeeded.\n",
        "\n",
        "        Criteria is the 3 equal actual and expected actions, should be after 5th step.\n",
        "        So we could act against the detected counter_attack_last_move agent.\n",
        "        \"\"\"\n",
        "        return anti_counter_attack_last_move_agent_auxiliary_marker == 1 and observation.step >= 5\n",
        "\n",
        "    def is_counter_attack_last_move_agent_detection_in_progress(anti_counter_attack_last_move_agent_auxiliary_marker,\n",
        "                                                                observation):\n",
        "        return anti_counter_attack_last_move_agent_auxiliary_marker == 1 and observation.step >= 2\n",
        "\n",
        "    if is_counter_attack_last_move_agent_detected(anti_counter_attack_last_move_agent_auxiliary_marker,\n",
        "                                                  observation):\n",
        "        return act_against_counter_attack_last_move_agent(anti_counter_attack_last_move_agent_moves,\n",
        "                                                          configuration)\n",
        "\n",
        "    elif is_counter_attack_last_move_agent_detection_in_progress(anti_counter_attack_last_move_agent_auxiliary_marker,\n",
        "                                                                 observation):\n",
        "        if is_counter_attack_last_move_agent_move_expected_equals_actual(configuration, observation,\n",
        "                                                                         anti_counter_attack_last_move_agent_moves):\n",
        "            move = np.random.randint(0, configuration.signs)\n",
        "            anti_counter_attack_last_move_agent_moves.append(move)\n",
        "        else:\n",
        "            anti_counter_attack_last_move_agent_auxiliary_marker = 0\n",
        "    elif anti_counter_attack_last_move_agent_auxiliary_marker == 1:\n",
        "        # Can't compare the calculated and actual opponents move before second step,so just save.\n",
        "        move = np.random.randint(0, configuration.signs)\n",
        "        anti_counter_attack_last_move_agent_moves.append(move)\n",
        "    else:\n",
        "        # Marker equals 0, so just return random, opponent probably is not the counter_attack_last_move agent.\n",
        "        move = np.random.randint(0, configuration.signs)\n",
        "\n",
        "        return move\n"
      ],
      "metadata": {
        "id": "fuDM-jdZwlKH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c0c0884-cf49-443d-e160-31be9a7582b1"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting anti_counter_attack_last_move.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile anti_mode.py\n",
        "import numpy as np\n",
        "\n",
        "anti_mode_auxiliary_marker = 1\n",
        "anti_mode_dictionary = dict().fromkeys([0, 1, 2], 0)\n",
        "\n",
        "\n",
        "def anti_mode(observation, configuration):\n",
        "    \"\"\"Gets action against mode agent.\n",
        "\n",
        "    Uses the anti_mode_dictionary to save the frequency distribution.\n",
        "    This rock-paper-scissors comparison functionality is so-called agent.\n",
        "    Agent could be used for competition by the kaggle_environments framework.\n",
        "    :param observation: observation object with auxiliary data\n",
        "    :param configuration: configuration object with game configuration\n",
        "    :return: int action to win mode agent action or random one (in detection criteria isn't verified)\n",
        "    \"\"\"\n",
        "\n",
        "    \"\"\"True if the anti_mode agent has been detected by this agent.\"\"\"\n",
        "    global anti_mode_auxiliary_marker\n",
        "\n",
        "    \"\"\"Dictionary to keep the agent moves.\"\"\"\n",
        "    global anti_mode_dictionary\n",
        "\n",
        "    def get_mode_agent_action_expected(configuration, mode_defence_dictionary):\n",
        "        \"\"\"Gets opponent expected action.\"\"\"\n",
        "        opponent_action_expected = (max(mode_defence_dictionary,\n",
        "                                        key=mode_defence_dictionary.get) + 1) % configuration.signs\n",
        "        return opponent_action_expected\n",
        "\n",
        "    def is_mode_agent_detection_in_progress(mode_defence_auxiliary_marker, observation):\n",
        "        \"\"\"Gets predicate to check if the criteria is not failed on the current step.\"\"\"\n",
        "        return observation.step > 1 and mode_defence_auxiliary_marker\n",
        "\n",
        "    def is_mode_agent_detected(mode_defence_auxiliary_marker, observation):\n",
        "        \"\"\"Gets predicate to check if mode attack agent criteria already verified.\"\"\"\n",
        "        return observation.step > 4 and mode_defence_auxiliary_marker == 1\n",
        "\n",
        "    def get_action_against_mode_agent(anti_mode_dictionary, configuration):\n",
        "        \"\"\"Gets action against mode agent.\"\"\"\n",
        "        return (max(anti_mode_dictionary, key=anti_mode_dictionary.get) + 2) % configuration.signs\n",
        "\n",
        "    if is_mode_agent_detected(anti_mode_auxiliary_marker, observation):\n",
        "        move = get_action_against_mode_agent(anti_mode_dictionary, configuration)\n",
        "        anti_mode_dictionary[move] += 1\n",
        "        return move\n",
        "    elif is_mode_agent_detection_in_progress(anti_mode_auxiliary_marker, observation):\n",
        "        opponents_expected_action = get_mode_agent_action_expected(configuration, anti_mode_dictionary)\n",
        "        if observation.lastOpponentAction == opponents_expected_action:\n",
        "            move = np.random.randint(0, configuration.signs)\n",
        "            anti_mode_dictionary[move] += 1\n",
        "            return move\n",
        "        else:\n",
        "            anti_mode_auxiliary_marker = 0\n",
        "            return np.random.randint(0, configuration.signs)\n",
        "    else:\n",
        "        move = np.random.randint(0, configuration.signs)\n",
        "        anti_mode_dictionary[move] += 1\n",
        "        return move\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xninU5NmyNrh",
        "outputId": "1520f0f4-e243-43dc-bd65-8b233677f525"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing anti_mode.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile anti_uniform_move.py\n",
        "import numpy as np\n",
        "\n",
        "uniform_move_detector_auxiliary_marker = 1\n",
        "opponent_move = None\n",
        "\n",
        "\n",
        "def anti_uniform_move(observation, configuration):\n",
        "    \"\"\"Gets action to win the similarly (uniformly) acting agent.\n",
        "\n",
        "    Detects uniform agent in 3 consecutive rounds.\n",
        "    Detects if the opponent uniform behaviour changes after detection criteria succeeded and does random moves.\n",
        "    Uses the mark to save the criteria check result.\n",
        "    This rock-paper-scissors comparison functionality is so-called agent.\n",
        "    Agent could be used for competition by the kaggle_environments framework.\n",
        "    :param observation: observation object with auxiliary data\n",
        "    :param configuration: configuration object with game configuration\n",
        "    :return: int action to win uniformly acting agent or random one (in detection criteria isn't verified)\n",
        "    \"\"\"\n",
        "\n",
        "    \"\"\"True if the uniformly acting agent (like rock or scissors agent) has been detected by this agent.\"\"\"\n",
        "    global uniform_move_detector_auxiliary_marker\n",
        "\n",
        "    \"\"\"Keeps opponent move.\"\"\"\n",
        "    global opponent_move\n",
        "\n",
        "    def is_uniformly_acting_agent_detected(observation, opponent_move,\n",
        "                                           uniform_move_detector_auxiliary_marker):\n",
        "        \"\"\"Gets predicate to check if uniform_move_detector agent criteria verified (3 similar moves in a row).\"\"\"\n",
        "        return observation.step > 4 and uniform_move_detector_auxiliary_marker \\\n",
        "               and observation.lastOpponentAction == opponent_move\n",
        "\n",
        "    def opponent_is_not_uniformly_acting(observation, opponent_move, uniform_move_detector_auxiliary_marker):\n",
        "        \"\"\"Gets predicate to check if opponent_is_not_uniformly_acting after first step.\"\"\"\n",
        "        return observation.step > 1 and uniform_move_detector_auxiliary_marker \\\n",
        "               and observation.lastOpponentAction != opponent_move\n",
        "\n",
        "    if is_uniformly_acting_agent_detected(observation, opponent_move,\n",
        "                                          uniform_move_detector_auxiliary_marker):\n",
        "        # action against agent with the same actions on every step\n",
        "        return (opponent_move + 1) % configuration.signs\n",
        "    elif opponent_is_not_uniformly_acting(observation, opponent_move, uniform_move_detector_auxiliary_marker):\n",
        "        uniform_move_detector_auxiliary_marker = 0\n",
        "    elif observation.step == 1:\n",
        "        opponent_move = observation.lastOpponentAction\n",
        "\n",
        "    return np.random.randint(0, configuration.signs)\n"
      ],
      "metadata": {
        "id": "7l6Ttw6qi0jk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7fb2126-fef7-4213-c954-589584f520b1"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting anti_uniform_move.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile arithmetic_average_attack.py\n",
        "import numpy as np\n",
        "\n",
        "arithmetic_average_attack_sum = 0\n",
        "arithmetic_average_attack_count = 0\n",
        "\n",
        "\n",
        "def arithmetic_average_attack(observation, configuration):\n",
        "    \"\"\"Gets action based on arithmetic last moves average estimate.\n",
        "\n",
        "    Uses the counters and cumulative sum saved on each step.\n",
        "    This rock-paper-scissors comparison functionality is so-called agent.\n",
        "    Agent could be used for competition by the kaggle_environments framework.\n",
        "    :param observation: observation object with auxiliary data\n",
        "    :param configuration: configuration object with game configuration\n",
        "    :return: int action, arithmetic average, or random one on the very first move\n",
        "    \"\"\"\n",
        "\n",
        "    \"\"\"Keeps arithmetic average attack sum.\"\"\"\n",
        "    global arithmetic_average_attack_sum\n",
        "\n",
        "    \"\"\"Keeps arithmetic average attack sum.\"\"\"\n",
        "    global arithmetic_average_attack_count\n",
        "\n",
        "    if observation.step > 0:\n",
        "        arithmetic_average_attack_sum += observation.lastOpponentAction\n",
        "        arithmetic_average_attack_count += 1\n",
        "        return int(arithmetic_average_attack_sum / arithmetic_average_attack_count)\n",
        "    else:\n",
        "        return np.random.randint(0, configuration.signs)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lxSmrTITq-wT",
        "outputId": "f879ea0b-5cd8-43ca-9770-e111f41cdc72"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting arithmetic_average_attack.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile counter_attack_last_move.py\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def counter_attack_last_move(observation, configuration):\n",
        "    \"\"\"Gets action to win the last opponents move.\n",
        "\n",
        "    This rock-paper-scissors comparison functionality is so-called agent.\n",
        "    Agent could be used for competition by the kaggle_environments framework.\n",
        "    :param observation: observation object with auxiliary data\n",
        "    :param configuration: configuration object with game configuration\n",
        "    :return: int action to win last opponent move or random if the first round\n",
        "    \"\"\"\n",
        "\n",
        "    def get_action_against(configuration, observation):\n",
        "        \"\"\" Gets action against last opponent action.\"\"\"\n",
        "        return (observation.lastOpponentAction + 1) % configuration.signs\n",
        "\n",
        "    if observation.step > 0:\n",
        "        return get_action_against(configuration, observation)\n",
        "    else:\n",
        "        return np.random.randint(0, configuration.signs)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4UPIVrFJra_g",
        "outputId": "3a4b6da4-5f84-4959-aff3-8359c79b69ce"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting counter_attack_last_move.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile mode.py\n",
        "import numpy as np\n",
        "\n",
        "mode_dictionary = dict().fromkeys([0, 1, 2], 0)\n",
        "\n",
        "\n",
        "def mode(observation, configuration):\n",
        "    \"\"\"Gets action based on the most frequent opponent move.\n",
        "\n",
        "    Uses the mode_dictionary to save the frequency distribution.\n",
        "    This rock-paper-scissors comparison functionality is so-called agent.\n",
        "    Agent could be used for competition by the kaggle_environments framework.\n",
        "    :param observation: observation object with auxiliary data\n",
        "    :param configuration: configuration object with game configuration\n",
        "    :return: int action to win opponents moves distribution mode or random one (if not enough data)\n",
        "    \"\"\"\n",
        "\n",
        "    \"\"\"Keeps opponent moves frequency distribution.\"\"\"\n",
        "    global mode_dictionary\n",
        "\n",
        "    def get_action_against_opponent_moves_distribution_mode(mode_dictionary, configuration):\n",
        "        \"\"\"Gets action against opponent moves by the mode estimate.\"\"\"\n",
        "        mode_value = max(mode_dictionary, key=mode_dictionary.get)\n",
        "        return (mode_value + 1) % configuration.signs\n",
        "\n",
        "    if observation.step > 1:\n",
        "        opponent_action = observation.lastOpponentAction\n",
        "        mode_dictionary[opponent_action] += 1\n",
        "        return get_action_against_opponent_moves_distribution_mode(mode_dictionary, configuration)\n",
        "    else:\n",
        "        return np.random.randint(0, configuration.signs)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R1f7DTisrkQu",
        "outputId": "4987beb7-bd80-4721-bb86-d19aba73348e"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting mode.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile opponent_imitator.py\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def opponent_imitator(observation, configuration):\n",
        "    \"\"\"Gets action from opponent last move (imitator).\n",
        "\n",
        "    This rock-paper-scissors comparison functionality is so-called agent.\n",
        "    Agent could be used for competition by the kaggle_environments framework.\n",
        "    :param observation: observation object with auxiliary data\n",
        "    :param configuration: configuration object with game configuration\n",
        "    :return: int action, opponent last move or random if the first round\n",
        "    \"\"\"\n",
        "\n",
        "    if observation.step == 0:\n",
        "        return np.random.randint(0, configuration.signs)\n",
        "    else:\n",
        "        return observation.lastOpponentAction\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SWFX-Vj8rmvM",
        "outputId": "79cca85b-96d6-4a3c-cd5f-8bcde95beaa2"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting opponent_imitator.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile paper.py\n",
        "def paper(observation, configuration):\n",
        "    \"\"\"Gets action 1 (so-called paper).\n",
        "\n",
        "    This rock-paper-scissors comparison functionality is so-called agent.\n",
        "    Agent could be used for competition by the kaggle_environments framework.\n",
        "    :param observation: observation object with auxiliary data\n",
        "    :param configuration: configuration object with game configuration\n",
        "    :return: 1\n",
        "    \"\"\"\n",
        "\n",
        "    return 1\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bxuaeCOkrqB_",
        "outputId": "a654df12-55a7-4fea-c988-78db5f27da65"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting paper.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile rock.py\n",
        "def rock(observation, configuration):\n",
        "    \"\"\"Gets action 0 (so-called rock).\n",
        "\n",
        "    This rock-paper-scissors comparison functionality is so-called agent.\n",
        "    Agent could be used for competition by the kaggle_environments framework.\n",
        "    :param observation: observation object with auxiliary data\n",
        "    :param configuration: configuration object with game configuration\n",
        "    :return: 0\n",
        "    \"\"\"\n",
        "\n",
        "    return 0\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xKluqs_zruve",
        "outputId": "22225bf8-eaaf-4b6c-cd0b-475f279fdb93"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting rock.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile scissors.py\n",
        "def scissors(observation, configuration):\n",
        "    \"\"\"Gets action 2 (so-called scissors).\n",
        "\n",
        "    This rock-paper-scissors comparison functionality is so-called agent.\n",
        "    Agent could be used for competition by the kaggle_environments framework.\n",
        "    :param observation: observation object with auxiliary data\n",
        "    :param configuration: configuration object with game configuration\n",
        "    :return: 2\n",
        "    \"\"\"\n",
        "\n",
        "    return 2\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QeL14HNDrxpU",
        "outputId": "17077c75-bf7f-4b3b-b8ea-474012d38a36"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting scissors.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile straight.py\n",
        "def straight(observation, configuration):\n",
        "    \"\"\"Gets action based on the step.\n",
        "\n",
        "    Returns the remainder of division of the step on configuration.signs.\n",
        "    So we have ascending combination, similar to straight hand in poker.\n",
        "    This rock-paper-scissors comparison functionality is so-called agent.\n",
        "    Agent could be used for competition by the kaggle_environments framework.\n",
        "    :param observation: observation object with auxiliary data\n",
        "    :param configuration: configuration object with game configuration\n",
        "    :return: int, action calculated from the step\n",
        "    \"\"\"\n",
        "\n",
        "    return observation.step % configuration.signs\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3KvDqjzpr3BF",
        "outputId": "1fbb7f5b-f62f-4706-ed4b-c8da9a5ef698"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting straight.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile uniform_random.py\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def uniform_random(observation, configuration):\n",
        "    \"\"\"Gets uniformly distributed value.\n",
        "\n",
        "    This rock-paper-scissors comparison functionality is so-called agent.\n",
        "    Agent could be used for competition by the kaggle_environments framework.\n",
        "    :param observation: observation object with auxiliary data\n",
        "    :param configuration: configuration object with game configuration\n",
        "    :return: int action, random move\n",
        "    \"\"\"\n",
        "\n",
        "    return np.random.randint(0, configuration.signs)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "je95l7JrsA-P",
        "outputId": "23ee5df7-c710-4e56-f35a-0891ff92b0e6"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting uniform_random.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class DuplicateAgentException(Exception):\n",
        "    pass\n",
        "\n",
        "\n",
        "class Tournament:\n",
        "    \"\"\"This is the Tournament class implemented as the directed weighted graph.\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"Constructor.\n",
        "\n",
        "        :param self: self\n",
        "        \"\"\"\n",
        "\n",
        "        self.map = dict()\n",
        "\n",
        "    def get_tournament_table(self):\n",
        "        \"\"\"Gets tournament table state (directed weighted graph).\n",
        "\n",
        "        :param self: self\n",
        "        :return: dictionary, tournament directed weighted graph\n",
        "        \"\"\"\n",
        "\n",
        "        return self.map\n",
        "\n",
        "    def add_agent(self, agent):\n",
        "        \"\"\"Adds agent to tournament.\n",
        "\n",
        "        :param self: self\n",
        "        :param agent: agent to add (identifier)\n",
        "        \"\"\"\n",
        "\n",
        "        if agent in self.map:\n",
        "            raise DuplicateAgentException(\"Duplicate agent\")\n",
        "        self.map[agent] = dict()\n",
        "\n",
        "    def get_agent(self, agent):\n",
        "        \"\"\"Gets agent from tournament table.\n",
        "\n",
        "        :param self: self\n",
        "        :param agent: agent identifier or name\n",
        "        :return: dictionary of agent games\n",
        "        \"\"\"\n",
        "\n",
        "        return self.map[agent]\n",
        "\n",
        "    def add_game_auxiliary(self, one, another, score):\n",
        "        \"\"\"Adds game result to the tournament for one side of the game.\n",
        "\n",
        "        :param self: self\n",
        "        :param one: one agent\n",
        "        :param another: another agent\n",
        "        :param score: score, positive, is the one agent is winner and negative if looser\n",
        "        \"\"\"\n",
        "\n",
        "        if one not in self.map:\n",
        "            self.add_agent(one)\n",
        "        agent_map = self.get_agent(one)\n",
        "        agent_map[another] = Game(one, another, score)\n",
        "\n",
        "    def add_game(self, one, another, score):\n",
        "        \"\"\"Adds game result to the tournament.\n",
        "\n",
        "        :param self: self\n",
        "        :param one: one agent\n",
        "        :param another: another agent\n",
        "        :param score: score, positive, is the one agent is winner and negative if looser\n",
        "        \"\"\"\n",
        "\n",
        "        self.add_game_auxiliary(one, another, score)\n",
        "        self.add_game_auxiliary(another, one, -score)\n",
        "\n",
        "    def get_winners_details(self):\n",
        "        \"\"\"Gets array of sorted by agent score descending tuples.\n",
        "\n",
        "        First value in each tuple item is agent name.\n",
        "        The second is the map of agent games with the data to get the sum.\n",
        "        :return: array of sorted tuples, tournament result with details\n",
        "        \"\"\"\n",
        "\n",
        "        return sorted(self.map.items(), key=lambda item: sum([z.score for z in item[1].values()]), reverse=True)\n",
        "\n",
        "    def get_winners(self):\n",
        "        \"\"\"Gets array of sorted by agent score descending tuples.\n",
        "\n",
        "        First value in each tuple item is agent name.\n",
        "        The second is the summ of agent scores.\n",
        "        :return: array of sorted tuples, tournament result if in short\n",
        "        \"\"\"\n",
        "        return [(item[0], sum([z.score for z in item[1].values()])) for item in self.get_winners_details()]\n",
        "\n",
        "    def get_winner(self):\n",
        "        \"\"\"Gets the tournament winner.\n",
        "\n",
        "        :param self: self\n",
        "        :return: winner agent identifier\n",
        "        \"\"\"\n",
        "\n",
        "        return \"Tournament winner: \" + str(self.get_winners_details()[0][0])\n",
        "\n",
        "\n",
        "class Game:\n",
        "    \"\"\"Game value-object class (though without hash-code reimplementation).\"\"\"\n",
        "\n",
        "    def __init__(self, one, loser, score):\n",
        "        \"\"\"Constructor.\n",
        "\n",
        "        :param one: one agent\n",
        "        :param loser: another agent\n",
        "        :param score: score, positive, is the one agent is winner and negative if looser\n",
        "        \"\"\"\n",
        "        self.one = one\n",
        "        self.another = loser\n",
        "        self.score = score\n",
        "\n",
        "    def __repr__(self):\n",
        "        \"\"\"Gets representation for the debugging purposes.\n",
        "\n",
        "        :return: string object representation\n",
        "        \"\"\"\n",
        "        return self.to_string()\n",
        "\n",
        "    def __str__(self):\n",
        "        \"\"\"Gets string object representation.\n",
        "\n",
        "        :return: string object representation\n",
        "        \"\"\"\n",
        "        return self.to_string()\n",
        "\n",
        "    def to_string(self):\n",
        "        \"\"\"Gets string object representation.\n",
        "\n",
        "        :return: string object representation\n",
        "        \"\"\"\n",
        "        return \"{one=\" + str(self.one) \\\n",
        "               + \"\\nanother=\" + str(self.another) \\\n",
        "               + \"\\nscore(positive, is one is winner, negative if looser)=\" + str(self.score) + \"}\"\n",
        "\n",
        "from kaggle_environments import evaluate\n",
        "\n",
        "\n",
        "class TournamentRunner:\n",
        "    \"\"\"This is the runner for the Tournament class.\"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def get_score(agents, configuration, i, j):\n",
        "        return evaluate(\n",
        "            \"rps\",\n",
        "            [agents[i], agents[j]],\n",
        "            configuration)[0][0]\n",
        "\n",
        "    @staticmethod\n",
        "    def run(tournament, agents, configuration):\n",
        "        \"\"\"Runs the tournament for the given agents and configuration.\n",
        "\n",
        "        Runs the tournament, prints the winner, winners list.\n",
        "\n",
        "        :param tournament: Tournament, tournament implementation\n",
        "        :param agents: list, agents participators\n",
        "        :param configuration: map, kaggle environment configuration\n",
        "        \"\"\"\n",
        "\n",
        "        for i in range(len(agents)):\n",
        "            for j in range(i + 1, len(agents)):\n",
        "                tournament.add_game(agents[i], agents[j], TournamentRunner.get_score(agents, configuration, i, j))\n",
        "\n",
        "        print(tournament.get_winner(), \"\\n\")\n",
        "\n",
        "        winners = tournament.get_winners()\n",
        "        [print(TournamentRunner.get_agent_result(i + 1, winners)) for i in range(len(winners))]\n",
        "\n",
        "    @staticmethod\n",
        "    def get_agent_result(position, winners):\n",
        "        \"\"\"Gets agent result string.\"\"\"\n",
        "        return str(position) + \" place: \" + str(winners[position - 1][0]) + \", score: \" + str(winners[position - 1][1])\n",
        "\n",
        "agents = [\n",
        "       \"scissors.py\",\n",
        "       \"paper.py\",\n",
        "       \"rock.py\",\n",
        "       \"opponent_imitator.py\",\n",
        "       \"uniform_random.py\",\n",
        "       \"counter_attack_last_move.py\",\n",
        "       \"anti_counter_attack_last_move.py\",\n",
        "       \"anti_uniform_move.py\",\n",
        "       \"mode.py\",\n",
        "       \"anti_mode.py\",\n",
        "       \"arithmetic_average_attack.py\",\n",
        "       \"ablaze.py\",\n",
        "       \"straight.py\"\n",
        "   ]\n",
        "configuration = {\"episodeSteps\": 16,\n",
        "                \"tieRewardThreshold\": 1}\n",
        "\n",
        "TournamentRunner().run(Tournament(), agents, configuration)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N4-zpLwJsZBF",
        "outputId": "fd81eb59-f10c-4066-e457-10618c9bd95a"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tournament winner: counter_attack_last_move.py \n",
            "\n",
            "1 place: counter_attack_last_move.py, score: 79.0\n",
            "2 place: mode.py, score: 39.0\n",
            "3 place: anti_uniform_move.py, score: 19.0\n",
            "4 place: straight.py, score: 15.0\n",
            "5 place: anti_counter_attack_last_move.py, score: 9.0\n",
            "6 place: ablaze.py, score: 5.0\n",
            "7 place: uniform_random.py, score: -8.0\n",
            "8 place: anti_mode.py, score: -9.0\n",
            "9 place: arithmetic_average_attack.py, score: -19.0\n",
            "10 place: rock.py, score: -23.0\n",
            "11 place: opponent_imitator.py, score: -24.0\n",
            "12 place: paper.py, score: -39.0\n",
            "13 place: scissors.py, score: -44.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jWoftIsJsjwo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Воспользуемся функцией evaluate из библиотеки kaggle_environments с помощью которой запустим наших агентов и проведем эксперимент на заданном количестве игр"
      ],
      "metadata": {
        "id": "ExgIpXUVjbjN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from kaggle_environments import make, evaluate\n",
        "\n",
        "evaluate(\n",
        "    \"rps\", #environment to use - no need to change\n",
        "    [\"paper_agent.py\", \"rock_agent.py\"], #agents to evaluate\n",
        "    configuration={\"episodeSteps\": 100} #number of episodes \n",
        ")"
      ],
      "metadata": {
        "id": "wv6Ip6M004xa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "afaf6484-28f2-484f-ca00-637f94d30ecf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[99.0, -99.0]]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    }
  ]
}