{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mavropulokn/functionsHw/blob/main/python_advanced_functions_HW_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "MXXTuy_o0sjk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b66bebc7-d384-44d7-9f3a-29ccfcba68b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 1.9 MB 26.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 62 kB 1.4 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q -U kaggle_environments"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Реализуем агентов."
      ],
      "metadata": {
        "id": "0kuo6IOxiRub"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile ablaze.py\n",
        "import numpy as np\n",
        "\n",
        "ablaze_combination_action = 0\n",
        "\n",
        "\n",
        "def ablaze(observation, configuration):\n",
        "    \"\"\"Gets action based on random selection (acts every configuration.signs steps, ablaze cycle).\n",
        "\n",
        "    After configuration.signs steps (combination) a cycle repeats.\n",
        "    Uses the ablaze_combination_action saved during each cycle.\n",
        "    This rock-paper-scissors comparison functionality is so-called agent.\n",
        "    Agent could be used for competition by the kaggle_environments framework.\n",
        "    :param observation: observation object with auxiliary data\n",
        "    :param configuration: configuration object with game configuration\n",
        "    :return: int action, new action selected during ablaze cycle\n",
        "    \"\"\"\n",
        "\n",
        "    # Action to repeat in series (combination) of steps.\n",
        "    global ablaze_combination_action\n",
        "\n",
        "    if observation.step % configuration.signs == 0:\n",
        "        ablaze_combination_action = np.random.randint(0, configuration.signs)\n",
        "    else:\n",
        "        return ablaze_combination_action\n"
      ],
      "metadata": {
        "id": "bqTqV7B92rJ6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a33e5254-2c3d-40f5-b75d-a1ea46b2f0e7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing ablaze.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile anti_counter_attack_last_move.py\n",
        "from collections import deque\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "anti_counter_attack_last_move_agent_auxiliary_marker = 1\n",
        "anti_counter_attack_last_move_agent_moves = deque(maxlen=2)\n",
        "opponent_moves = deque(maxlen=1)\n",
        "\n",
        "\n",
        "def anti_counter_attack_last_move(observation, configuration):\n",
        "    \"\"\"Gets action to win the counter_attack_last_move agent.\n",
        "\n",
        "    Detects counter_attack_last_move agent (tested in 3 consecutive rounds).\n",
        "    Uses the queue to save last 2 actions and mark to save the criteria check result.\n",
        "    This rock-paper-scissors comparison functionality is so-called agent.\n",
        "    Agent could be used for competition by the kaggle_environments framework.\n",
        "    :param observation: observation object with auxiliary data\n",
        "    :param configuration: configuration object with game configuration\n",
        "    :return: int action to win counter_attack_last_move agent or random one (in detection criteria isn't verified)\n",
        "    \"\"\"\n",
        "\n",
        "    # Queue to save last 2 actions.\n",
        "    global anti_counter_attack_last_move_agent_moves\n",
        "\n",
        "    # Mark to save the criteria validation.\n",
        "    global anti_counter_attack_last_move_agent_auxiliary_marker\n",
        "\n",
        "    def is_counter_attack_last_move_agent_move_expected_equals_actual(configuration, observation,\n",
        "                                                                      counter_attack_defencemoves):\n",
        "        \"\"\"Gets predicate or to check if the opponent could be counter_attack_last_move agent.\"\"\"\n",
        "        return observation.lastOpponentAction == (\n",
        "                counter_attack_defencemoves.popleft() + 1) % configuration.signs\n",
        "\n",
        "    def act_against_counter_attack_last_move_agent(anti_counter_attack_last_move_agent_moves, configuration):\n",
        "        \"\"\"Gets action against counter_attack_last_move agent, saves action and returns.\"\"\"\n",
        "\n",
        "        action = (anti_counter_attack_last_move_agent_moves.popleft() + 2) % configuration.signs\n",
        "        anti_counter_attack_last_move_agent_moves.append(action)\n",
        "        return action\n",
        "\n",
        "    def is_counter_attack_last_move_agent_detected(anti_counter_attack_last_move_agent_auxiliary_marker,\n",
        "                                                   observation):\n",
        "        \"\"\"Checks the counter_attack_last_move_agent detection criteria has succeeded.\n",
        "\n",
        "        Criteria is the 3 equal actual and expected actions, should be after 5th step.\n",
        "        So we could act against the detected counter_attack_last_move agent.\n",
        "        \"\"\"\n",
        "        return anti_counter_attack_last_move_agent_auxiliary_marker == 1 and observation.step >= 5\n",
        "\n",
        "    def is_counter_attack_last_move_agent_detection_in_progress(anti_counter_attack_last_move_agent_auxiliary_marker,\n",
        "                                                                observation):\n",
        "        return anti_counter_attack_last_move_agent_auxiliary_marker == 1 and observation.step >= 2\n",
        "\n",
        "    if is_counter_attack_last_move_agent_detected(anti_counter_attack_last_move_agent_auxiliary_marker,\n",
        "                                                  observation):\n",
        "        return act_against_counter_attack_last_move_agent(anti_counter_attack_last_move_agent_moves,\n",
        "                                                          configuration)\n",
        "\n",
        "    elif is_counter_attack_last_move_agent_detection_in_progress(anti_counter_attack_last_move_agent_auxiliary_marker,\n",
        "                                                                 observation):\n",
        "        if is_counter_attack_last_move_agent_move_expected_equals_actual(configuration, observation,\n",
        "                                                                         anti_counter_attack_last_move_agent_moves):\n",
        "            move = np.random.randint(0, configuration.signs)\n",
        "            anti_counter_attack_last_move_agent_moves.append(move)\n",
        "        else:\n",
        "            anti_counter_attack_last_move_agent_auxiliary_marker = 0\n",
        "    elif anti_counter_attack_last_move_agent_auxiliary_marker == 1:\n",
        "        # Can't compare the calculated and actual opponents move before second step,so just save.\n",
        "        move = np.random.randint(0, configuration.signs)\n",
        "        anti_counter_attack_last_move_agent_moves.append(move)\n",
        "    else:\n",
        "        # Marker equals 0, so just return random, opponent probably is not the counter_attack_last_move agent.\n",
        "        move = np.random.randint(0, configuration.signs)\n",
        "\n",
        "        return move\n"
      ],
      "metadata": {
        "id": "fuDM-jdZwlKH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dcf0ffe0-f6bb-49b5-ac4b-1380139598a0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing anti_counter_attack_last_move.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile anti_mode.py\n",
        "import numpy as np\n",
        "\n",
        "anti_mode_auxiliary_marker = 1\n",
        "anti_mode_dictionary = dict().fromkeys([0, 1, 2], 0)\n",
        "\n",
        "\n",
        "def anti_mode(observation, configuration):\n",
        "    \"\"\"Gets action against mode agent.\n",
        "\n",
        "    Uses the anti_mode_dictionary to save the frequency distribution.\n",
        "    This rock-paper-scissors comparison functionality is so-called agent.\n",
        "    Agent could be used for competition by the kaggle_environments framework.\n",
        "    :param observation: observation object with auxiliary data\n",
        "    :param configuration: configuration object with game configuration\n",
        "    :return: int action to win mode agent action or random one (in detection criteria isn't verified)\n",
        "    \"\"\"\n",
        "\n",
        "    \"\"\"True if the anti_mode agent has been detected by this agent.\"\"\"\n",
        "    global anti_mode_auxiliary_marker\n",
        "\n",
        "    \"\"\"Dictionary to keep the agent moves.\"\"\"\n",
        "    global anti_mode_dictionary\n",
        "\n",
        "    def get_mode_agent_action_expected(configuration, mode_defence_dictionary):\n",
        "        \"\"\"Gets opponent expected action.\"\"\"\n",
        "        opponent_action_expected = (max(mode_defence_dictionary,\n",
        "                                        key=mode_defence_dictionary.get) + 1) % configuration.signs\n",
        "        return opponent_action_expected\n",
        "\n",
        "    def is_mode_agent_detection_in_progress(mode_defence_auxiliary_marker, observation):\n",
        "        \"\"\"Gets predicate to check if the criteria is not failed on the current step.\"\"\"\n",
        "        return observation.step > 1 and mode_defence_auxiliary_marker\n",
        "\n",
        "    def is_mode_agent_detected(mode_defence_auxiliary_marker, observation):\n",
        "        \"\"\"Gets predicate to check if mode attack agent criteria already verified.\"\"\"\n",
        "        return observation.step > 4 and mode_defence_auxiliary_marker == 1\n",
        "\n",
        "    def get_action_against_mode_agent(anti_mode_dictionary, configuration):\n",
        "        \"\"\"Gets action against mode agent.\"\"\"\n",
        "        return (max(anti_mode_dictionary, key=anti_mode_dictionary.get) + 2) % configuration.signs\n",
        "\n",
        "    if is_mode_agent_detected(anti_mode_auxiliary_marker, observation):\n",
        "        move = get_action_against_mode_agent(anti_mode_dictionary, configuration)\n",
        "        anti_mode_dictionary[move] += 1\n",
        "        return move\n",
        "    elif is_mode_agent_detection_in_progress(anti_mode_auxiliary_marker, observation):\n",
        "        opponents_expected_action = get_mode_agent_action_expected(configuration, anti_mode_dictionary)\n",
        "        if observation.lastOpponentAction == opponents_expected_action:\n",
        "            move = np.random.randint(0, configuration.signs)\n",
        "            anti_mode_dictionary[move] += 1\n",
        "            return move\n",
        "        else:\n",
        "            anti_mode_auxiliary_marker = 0\n",
        "            return np.random.randint(0, configuration.signs)\n",
        "    else:\n",
        "        move = np.random.randint(0, configuration.signs)\n",
        "        anti_mode_dictionary[move] += 1\n",
        "        return move\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xninU5NmyNrh",
        "outputId": "b63404f7-007c-41a0-e484-54614808086d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing anti_mode.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile anti_uniform_move.py\n",
        "import numpy as np\n",
        "\n",
        "uniform_move_detector_auxiliary_marker = 1\n",
        "opponent_move = None\n",
        "\n",
        "\n",
        "def anti_uniform_move(observation, configuration):\n",
        "    \"\"\"Gets action to win the similarly (uniformly) acting agent.\n",
        "\n",
        "    Detects uniform agent in 3 consecutive rounds.\n",
        "    Detects if the opponent uniform behaviour changes after detection criteria succeeded and does random moves.\n",
        "    Uses the mark to save the criteria check result.\n",
        "    This rock-paper-scissors comparison functionality is so-called agent.\n",
        "    Agent could be used for competition by the kaggle_environments framework.\n",
        "    :param observation: observation object with auxiliary data\n",
        "    :param configuration: configuration object with game configuration\n",
        "    :return: int action to win uniformly acting agent or random one (in detection criteria isn't verified)\n",
        "    \"\"\"\n",
        "\n",
        "    \"\"\"True if the uniformly acting agent (like rock or scissors agent) has been detected by this agent.\"\"\"\n",
        "    global uniform_move_detector_auxiliary_marker\n",
        "\n",
        "    \"\"\"Keeps opponent move.\"\"\"\n",
        "    global opponent_move\n",
        "\n",
        "    def is_uniformly_acting_agent_detected(observation, opponent_move,\n",
        "                                           uniform_move_detector_auxiliary_marker):\n",
        "        \"\"\"Gets predicate to check if uniform_move_detector agent criteria verified (3 similar moves in a row).\"\"\"\n",
        "        return observation.step > 4 and uniform_move_detector_auxiliary_marker \\\n",
        "               and observation.lastOpponentAction == opponent_move\n",
        "\n",
        "    def opponent_is_not_uniformly_acting(observation, opponent_move, uniform_move_detector_auxiliary_marker):\n",
        "        \"\"\"Gets predicate to check if opponent_is_not_uniformly_acting after first step.\"\"\"\n",
        "        return observation.step > 1 and uniform_move_detector_auxiliary_marker \\\n",
        "               and observation.lastOpponentAction != opponent_move\n",
        "\n",
        "    if is_uniformly_acting_agent_detected(observation, opponent_move,\n",
        "                                          uniform_move_detector_auxiliary_marker):\n",
        "        # action against agent with the same actions on every step\n",
        "        return (opponent_move + 1) % configuration.signs\n",
        "    elif opponent_is_not_uniformly_acting(observation, opponent_move, uniform_move_detector_auxiliary_marker):\n",
        "        uniform_move_detector_auxiliary_marker = 0\n",
        "    elif observation.step == 1:\n",
        "        opponent_move = observation.lastOpponentAction\n",
        "\n",
        "    return np.random.randint(0, configuration.signs)\n"
      ],
      "metadata": {
        "id": "7l6Ttw6qi0jk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49c6c42c-40f0-4ea2-85cb-0a3807b3cb36"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing anti_uniform_move.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile arithmetic_average_attack.py\n",
        "import numpy as np\n",
        "\n",
        "arithmetic_average_attack_sum = 0\n",
        "arithmetic_average_attack_count = 0\n",
        "\n",
        "\n",
        "def arithmetic_average_attack(observation, configuration):\n",
        "    \"\"\"Gets action based on arithmetic last moves average estimate.\n",
        "\n",
        "    Uses the counters and cumulative sum saved on each step.\n",
        "    This rock-paper-scissors comparison functionality is so-called agent.\n",
        "    Agent could be used for competition by the kaggle_environments framework.\n",
        "    :param observation: observation object with auxiliary data\n",
        "    :param configuration: configuration object with game configuration\n",
        "    :return: int action, arithmetic average, or random one on the very first move\n",
        "    \"\"\"\n",
        "\n",
        "    \"\"\"Keeps arithmetic average attack sum.\"\"\"\n",
        "    global arithmetic_average_attack_sum\n",
        "\n",
        "    \"\"\"Keeps arithmetic average attack sum.\"\"\"\n",
        "    global arithmetic_average_attack_count\n",
        "\n",
        "    if observation.step > 0:\n",
        "        arithmetic_average_attack_sum += observation.lastOpponentAction\n",
        "        arithmetic_average_attack_count += 1\n",
        "        return int(arithmetic_average_attack_sum / arithmetic_average_attack_count)\n",
        "    else:\n",
        "        return np.random.randint(0, configuration.signs)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lxSmrTITq-wT",
        "outputId": "4328b85f-cb64-4ce0-c3fa-dab62e352a65"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing arithmetic_average_attack.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile counter_attack_last_move.py\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def counter_attack_last_move(observation, configuration):\n",
        "    \"\"\"Gets action to win the last opponents move.\n",
        "\n",
        "    This rock-paper-scissors comparison functionality is so-called agent.\n",
        "    Agent could be used for competition by the kaggle_environments framework.\n",
        "    :param observation: observation object with auxiliary data\n",
        "    :param configuration: configuration object with game configuration\n",
        "    :return: int action to win last opponent move or random if the first round\n",
        "    \"\"\"\n",
        "\n",
        "    def get_action_against(configuration, observation):\n",
        "        \"\"\" Gets action against last opponent action.\"\"\"\n",
        "        return (observation.lastOpponentAction + 1) % configuration.signs\n",
        "\n",
        "    if observation.step > 0:\n",
        "        return get_action_against(configuration, observation)\n",
        "    else:\n",
        "        return np.random.randint(0, configuration.signs)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4UPIVrFJra_g",
        "outputId": "ce4162c9-bcdd-4754-c0ce-44e4fa55048e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing counter_attack_last_move.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile mode.py\n",
        "import numpy as np\n",
        "\n",
        "mode_dictionary = dict().fromkeys([0, 1, 2], 0)\n",
        "\n",
        "\n",
        "def mode(observation, configuration):\n",
        "    \"\"\"Gets action based on the most frequent opponent move.\n",
        "\n",
        "    Uses the mode_dictionary to save the frequency distribution.\n",
        "    This rock-paper-scissors comparison functionality is so-called agent.\n",
        "    Agent could be used for competition by the kaggle_environments framework.\n",
        "    :param observation: observation object with auxiliary data\n",
        "    :param configuration: configuration object with game configuration\n",
        "    :return: int action to win opponents moves distribution mode or random one (if not enough data)\n",
        "    \"\"\"\n",
        "\n",
        "    \"\"\"Keeps opponent moves frequency distribution.\"\"\"\n",
        "    global mode_dictionary\n",
        "\n",
        "    def get_action_against_opponent_moves_distribution_mode(mode_dictionary, configuration):\n",
        "        \"\"\"Gets action against opponent moves by the mode estimate.\"\"\"\n",
        "        mode_value = max(mode_dictionary, key=mode_dictionary.get)\n",
        "        return (mode_value + 1) % configuration.signs\n",
        "\n",
        "    if observation.step > 1:\n",
        "        opponent_action = observation.lastOpponentAction\n",
        "        mode_dictionary[opponent_action] += 1\n",
        "        return get_action_against_opponent_moves_distribution_mode(mode_dictionary, configuration)\n",
        "    else:\n",
        "        return np.random.randint(0, configuration.signs)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R1f7DTisrkQu",
        "outputId": "d90c21f2-077d-406e-f19e-bdc2250f5b5e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing mode.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile opponent_imitator.py\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def opponent_imitator(observation, configuration):\n",
        "    \"\"\"Gets action from opponent last move (imitator).\n",
        "\n",
        "    This rock-paper-scissors comparison functionality is so-called agent.\n",
        "    Agent could be used for competition by the kaggle_environments framework.\n",
        "    :param observation: observation object with auxiliary data\n",
        "    :param configuration: configuration object with game configuration\n",
        "    :return: int action, opponent last move or random if the first round\n",
        "    \"\"\"\n",
        "\n",
        "    if observation.step == 0:\n",
        "        return np.random.randint(0, configuration.signs)\n",
        "    else:\n",
        "        return observation.lastOpponentAction\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SWFX-Vj8rmvM",
        "outputId": "8394edc8-7181-4c8c-b3ce-e323b27dc09b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing opponent_imitator.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile paper.py\n",
        "def paper(observation, configuration):\n",
        "    \"\"\"Gets action 1 (so-called paper).\n",
        "\n",
        "    This rock-paper-scissors comparison functionality is so-called agent.\n",
        "    Agent could be used for competition by the kaggle_environments framework.\n",
        "    :param observation: observation object with auxiliary data\n",
        "    :param configuration: configuration object with game configuration\n",
        "    :return: 1\n",
        "    \"\"\"\n",
        "\n",
        "    return 1\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bxuaeCOkrqB_",
        "outputId": "1f972e52-67de-4977-f7f2-ae66b7688799"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing paper.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile rock.py\n",
        "def rock(observation, configuration):\n",
        "    \"\"\"Gets action 0 (so-called rock).\n",
        "\n",
        "    This rock-paper-scissors comparison functionality is so-called agent.\n",
        "    Agent could be used for competition by the kaggle_environments framework.\n",
        "    :param observation: observation object with auxiliary data\n",
        "    :param configuration: configuration object with game configuration\n",
        "    :return: 0\n",
        "    \"\"\"\n",
        "\n",
        "    return 0\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xKluqs_zruve",
        "outputId": "f40e3b3b-0737-4616-db42-42ccea55c31e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing rock.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile scissors.py\n",
        "def scissors(observation, configuration):\n",
        "    \"\"\"Gets action 2 (so-called scissors).\n",
        "\n",
        "    This rock-paper-scissors comparison functionality is so-called agent.\n",
        "    Agent could be used for competition by the kaggle_environments framework.\n",
        "    :param observation: observation object with auxiliary data\n",
        "    :param configuration: configuration object with game configuration\n",
        "    :return: 2\n",
        "    \"\"\"\n",
        "\n",
        "    return 2\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QeL14HNDrxpU",
        "outputId": "63e59e24-dc22-45cf-ad18-c90bcf8fdb17"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing scissors.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile straight.py\n",
        "def straight(observation, configuration):\n",
        "    \"\"\"Gets action based on the step.\n",
        "\n",
        "    Returns the remainder of division of the step on configuration.signs.\n",
        "    So we have ascending combination, similar to straight hand in poker.\n",
        "    This rock-paper-scissors comparison functionality is so-called agent.\n",
        "    Agent could be used for competition by the kaggle_environments framework.\n",
        "    :param observation: observation object with auxiliary data\n",
        "    :param configuration: configuration object with game configuration\n",
        "    :return: int, action calculated from the step\n",
        "    \"\"\"\n",
        "\n",
        "    return observation.step % configuration.signs\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3KvDqjzpr3BF",
        "outputId": "bb020cd5-a637-4ee4-d8e2-6930de9413fb"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing straight.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile uniform_random.py\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def uniform_random(observation, configuration):\n",
        "    \"\"\"Gets uniformly distributed value.\n",
        "\n",
        "    This rock-paper-scissors comparison functionality is so-called agent.\n",
        "    Agent could be used for competition by the kaggle_environments framework.\n",
        "    :param observation: observation object with auxiliary data\n",
        "    :param configuration: configuration object with game configuration\n",
        "    :return: int action, random move\n",
        "    \"\"\"\n",
        "\n",
        "    return np.random.randint(0, configuration.signs)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "je95l7JrsA-P",
        "outputId": "c92137b2-1899-4423-c926-3d9ba6c0fdab"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing uniform_random.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Реализуем турнирную доску, запускатор турнира, запустим турнир и выведем результаты."
      ],
      "metadata": {
        "id": "foi8Whu85rQ9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DuplicateAgentException(Exception):\n",
        "    pass\n",
        "\n",
        "\n",
        "class Tournament:\n",
        "    \"\"\"This is the Tournament class implemented as the directed weighted graph.\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"Constructor.\n",
        "\n",
        "        :param self: self\n",
        "        \"\"\"\n",
        "\n",
        "        self.map = dict()\n",
        "\n",
        "    def get_tournament_table(self):\n",
        "        \"\"\"Gets tournament table state (directed weighted graph).\n",
        "\n",
        "        :param self: self\n",
        "        :return: dictionary, tournament directed weighted graph\n",
        "        \"\"\"\n",
        "\n",
        "        return self.map\n",
        "\n",
        "    def add_agent(self, agent):\n",
        "        \"\"\"Adds agent to tournament.\n",
        "\n",
        "        :param self: self\n",
        "        :param agent: agent to add (identifier)\n",
        "        \"\"\"\n",
        "\n",
        "        if agent in self.map:\n",
        "            raise DuplicateAgentException(\"Duplicate agent\")\n",
        "        self.map[agent] = dict()\n",
        "\n",
        "    def get_agent(self, agent):\n",
        "        \"\"\"Gets agent from tournament table.\n",
        "\n",
        "        :param self: self\n",
        "        :param agent: agent identifier or name\n",
        "        :return: dictionary of agent games\n",
        "        \"\"\"\n",
        "\n",
        "        return self.map[agent]\n",
        "\n",
        "    def add_game_auxiliary(self, one, another, score):\n",
        "        \"\"\"Adds game result to the tournament for one side of the game.\n",
        "\n",
        "        :param self: self\n",
        "        :param one: one agent\n",
        "        :param another: another agent\n",
        "        :param score: score, positive, is the one agent is winner and negative if looser\n",
        "        \"\"\"\n",
        "\n",
        "        if one not in self.map:\n",
        "            self.add_agent(one)\n",
        "        agent_map = self.get_agent(one)\n",
        "        agent_map[another] = Game(one, another, score)\n",
        "\n",
        "    def add_game(self, one, another, score):\n",
        "        \"\"\"Adds game result to the tournament.\n",
        "\n",
        "        :param self: self\n",
        "        :param one: one agent\n",
        "        :param another: another agent\n",
        "        :param score: score, positive, is the one agent is winner and negative if looser\n",
        "        \"\"\"\n",
        "\n",
        "        self.add_game_auxiliary(one, another, score)\n",
        "        self.add_game_auxiliary(another, one, -score)\n",
        "\n",
        "    def get_winners_details(self):\n",
        "        \"\"\"Gets array of sorted by agent score descending tuples.\n",
        "\n",
        "        First value in each tuple item is agent name.\n",
        "        The second is the map of agent games with the data to get the sum.\n",
        "        :return: array of sorted tuples, tournament result with details\n",
        "        \"\"\"\n",
        "\n",
        "        return sorted(self.map.items(), key=lambda item: sum([z.score for z in item[1].values()]), reverse=True)\n",
        "\n",
        "    def get_winners(self):\n",
        "        \"\"\"Gets array of sorted by agent score descending tuples.\n",
        "\n",
        "        First value in each tuple item is agent name.\n",
        "        The second is the summ of agent scores.\n",
        "        :return: array of sorted tuples, tournament result if in short\n",
        "        \"\"\"\n",
        "        return [(item[0], sum([z.score for z in item[1].values()])) for item in self.get_winners_details()]\n",
        "\n",
        "    def get_winner(self):\n",
        "        \"\"\"Gets the tournament winner.\n",
        "\n",
        "        :param self: self\n",
        "        :return: winner agent identifier\n",
        "        \"\"\"\n",
        "\n",
        "        return \"Tournament winner: \" + str(self.get_winners_details()[0][0])\n",
        "\n",
        "\n",
        "class Game:\n",
        "    \"\"\"Game value-object class (though without hash-code reimplementation).\"\"\"\n",
        "\n",
        "    def __init__(self, one, loser, score):\n",
        "        \"\"\"Constructor.\n",
        "\n",
        "        :param one: one agent\n",
        "        :param loser: another agent\n",
        "        :param score: score, positive, is the one agent is winner and negative if looser\n",
        "        \"\"\"\n",
        "        self.one = one\n",
        "        self.another = loser\n",
        "        self.score = score\n",
        "\n",
        "    def __repr__(self):\n",
        "        \"\"\"Gets representation for the debugging purposes.\n",
        "\n",
        "        :return: string object representation\n",
        "        \"\"\"\n",
        "        return self.to_string()\n",
        "\n",
        "    def __str__(self):\n",
        "        \"\"\"Gets string object representation.\n",
        "\n",
        "        :return: string object representation\n",
        "        \"\"\"\n",
        "        return self.to_string()\n",
        "\n",
        "    def to_string(self):\n",
        "        \"\"\"Gets string object representation.\n",
        "\n",
        "        :return: string object representation\n",
        "        \"\"\"\n",
        "        return \"{one=\" + str(self.one) \\\n",
        "               + \"\\nanother=\" + str(self.another) \\\n",
        "               + \"\\nscore(positive, is one is winner, negative if looser)=\" + str(self.score) + \"}\"\n",
        "\n",
        "from kaggle_environments import evaluate\n",
        "\n",
        "\n",
        "class TournamentRunner:\n",
        "    \"\"\"This is the runner for the Tournament class.\"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def get_score(agents, configuration, i, j):\n",
        "        return evaluate(\n",
        "            \"rps\",\n",
        "            [agents[i], agents[j]],\n",
        "            configuration)[0][0]\n",
        "\n",
        "    @staticmethod\n",
        "    def run(tournament, agents, configuration):\n",
        "        \"\"\"Runs the tournament for the given agents and configuration.\n",
        "\n",
        "        Runs the tournament, prints the winner, winners list.\n",
        "\n",
        "        :param tournament: Tournament, tournament implementation\n",
        "        :param agents: list, agents participators\n",
        "        :param configuration: map, kaggle environment configuration\n",
        "        \"\"\"\n",
        "\n",
        "        for i in range(len(agents)):\n",
        "            for j in range(i + 1, len(agents)):\n",
        "                tournament.add_game(agents[i], agents[j], TournamentRunner.get_score(agents, configuration, i, j))\n",
        "\n",
        "        print(tournament.get_winner(), \"\\n\")\n",
        "\n",
        "        winners = tournament.get_winners()\n",
        "        [print(TournamentRunner.get_agent_result(i + 1, winners)) for i in range(len(winners))]\n",
        "\n",
        "    @staticmethod\n",
        "    def get_agent_result(position, winners):\n",
        "        \"\"\"Gets agent result string.\"\"\"\n",
        "        return str(position) + \" place: \" + str(winners[position - 1][0]) + \", score: \" + str(winners[position - 1][1])\n",
        "\n",
        "agents = [\n",
        "       \"scissors.py\",\n",
        "       \"paper.py\",\n",
        "       \"rock.py\",\n",
        "       \"opponent_imitator.py\",\n",
        "       \"uniform_random.py\",\n",
        "       \"counter_attack_last_move.py\",\n",
        "       \"anti_counter_attack_last_move.py\",\n",
        "       \"anti_uniform_move.py\",\n",
        "       \"mode.py\",\n",
        "       \"anti_mode.py\",\n",
        "       \"arithmetic_average_attack.py\",\n",
        "       \"ablaze.py\",\n",
        "       \"straight.py\"\n",
        "   ]\n",
        "configuration = {\"episodeSteps\": 16,\n",
        "                \"tieRewardThreshold\": 1}\n",
        "\n",
        "TournamentRunner().run(Tournament(), agents, configuration)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N4-zpLwJsZBF",
        "outputId": "54293714-2a1e-4edc-80e0-838453da36c9"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tournament winner: anti_uniform_move.py \n",
            "\n",
            "1 place: anti_uniform_move.py, score: 68.0\n",
            "2 place: mode.py, score: 56.0\n",
            "3 place: counter_attack_last_move.py, score: 50.0\n",
            "4 place: straight.py, score: 12.0\n",
            "5 place: opponent_imitator.py, score: 1.0\n",
            "6 place: arithmetic_average_attack.py, score: -9.0\n",
            "7 place: anti_counter_attack_last_move.py, score: -17.0\n",
            "8 place: anti_mode.py, score: -17.0\n",
            "9 place: uniform_random.py, score: -18.0\n",
            "10 place: rock.py, score: -30.0\n",
            "11 place: paper.py, score: -31.0\n",
            "12 place: ablaze.py, score: -31.0\n",
            "13 place: scissors.py, score: -34.0\n"
          ]
        }
      ]
    }
  ]
}